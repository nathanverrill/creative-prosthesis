# Lyrics Lab

Creative Prosthesis

Nathan Verrill / Azro Leclaire

October 2025

## ğŸ¤ Lyrics Lab Backend

A containerized Python backend that powers a collaborative, agent-inspired songwriting assistant.  
You provide a theme and a hook, and get structured, versioned, and traceable lyrics â€” ready for platforms like [Suno](https://www.suno.ai).

---

## ğŸš€ Features

- âœï¸ Theme-based song lyric generation using local LLMs via [Ollama](https://ollama.com)
- ğŸ§  Line-level tracking of author, version history, and scoring (e.g. creativity, quality)
- ğŸ‘¥ Multi-role inspired collaboration (lyricist, brainstormers, critic, etc.)
- ğŸ“Š Finalization with authorship ratio (for copyright/disclosure purposes)
- ğŸ³ Fully containerized with Docker
- âš™ï¸ Configurable LLM backend (e.g., `llama3.1`, `mistral-nemo`, etc.)

---

## ğŸ“ Project Structure

```
lyric-lab-backend/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ api.py            # FastAPI routes
â”‚   â”œâ”€â”€ llm.py            # LLM integration via Ollama
â”‚   â”œâ”€â”€ models.py         # Pydantic models (Line, Document, History)
â”‚   â”œâ”€â”€ scoring.py        # Line scoring (quality, creativity, etc.)
â”‚   â””â”€â”€ __init__.py
â”œâ”€â”€ config.yaml           # LLM configuration
â”œâ”€â”€ Dockerfile            # For container builds
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

---

## ğŸ› ï¸ Configuration

Edit `config.yaml` to set your preferred LLM model:

```yaml
llm_provider: ollama
llm_model: llama3.1 # or mistral-nemo
```

Ollama must be running the model locally (e.g. `ollama run llama3.1`).

---

## ğŸ³ Run with Docker

Build and run the backend:

```bash
docker build -t lyriclab .
docker run -p 8000:8000 lyriclab
```

---

## ğŸ§ª API Endpoints

### `POST /generate/lyrics`

Generate a new draft from theme + hook

**Query Params:**

- `theme`: `"quantum physics at F1"`
- `hook`: `"this is the hook, damnit"`

**Response:**  
Returns a structured `LyricDocument` with line history and scoring.

---

### `GET /finalize/song`

Calculate authorship ratio and produce final output (based on in-memory song)

**Response:**

```json
{
  "status": "finalized",
  "lines": 14,
  "authorship_ratio": 0.21,
  "final_lyrics": "... lyrics as string ..."
}
```

> âš ï¸ Requires a song to have been previously generated.

---

## ğŸ”® Planned Features

- [ ] A/B testing hook selection before writing
- [ ] Integration with UI for editing & visualization
- [ ] Voice/adlib tags per line (e.g. â€œDanny Ric voiceâ€)
- [ ] Custom agents using CrewAI

---

## ğŸ“ Attribution Use Case

Use the `authorship_ratio` to prove â‰¥51% human input when required for:

- IP rights under digital copyright laws
- Editorial accountability
- Creative debates ğŸ˜

---

## âœ… Requirements

- Python 3.11+
- Docker
- Ollama with your models (e.g. `llama3`, `mistral`, etc.)

---

## ğŸ’¬ Questions?

Youâ€™re building something awesome. If you need:

- API tweaks
- Ollama prompt tuning
- CrewAI-based song generators

â†’ just ask!
