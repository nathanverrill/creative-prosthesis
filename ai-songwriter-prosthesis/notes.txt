Perplexity for the fact

Grok for the writer - make it an agentic rap battle

Songwriter personality / Band

Band can be the multi-hats

And that includes the researcher / and fact checker

Use gemini batch api for the parallel brainstorm?


Example request
{
  "theme": "nacho libre",
  "mood": "chipper",
  "draft_lyrics": ["macho macho man, nacho nacho libre", "wonder how much I'll win by", "shit was on rails, thought I was gonna fly","in sync millennium, bye bye bye"]
}

Example structure

{
  "theme": "lucha libre",
  "mood": "asshole",
  "draft_lyrics": [
    "macho macho man, nacho nacho libre",
    "wonder how much I'll win by.",
    "shit was on rails, thought I was gonna fly",
    "in sync millennium, bye bye bye"
  ]
}

Present user with opening verse options; user chooses which one they prefer; that one is used in the creation prompt, to follow that vibe style

The two options are editable so user can tweak them, still tracking human vs machine

Save user preferences to get smarter? Like history of what the user likes for references?

Ability for critics to suggest changes to individual lines. Do we then change them outright, or give the songwriter a set of revisions to choose from, if they make sense in the larger context?

Stream back the result

Entry form for filling in sections, or lyric lines -- optional

Then sections are kept as, and the machine fills them in 

Return version that is 'from scratch' based on the theme, and another that's filled in with the human-provided components

Get meme - can just enter it along with the quotes

Should theme be "inspiration"?

With feature that has if use verbatim to have it in quotes

Line number corrections


Different temps / model settings for the persona types (e.g., facts vs creativity)


docker run -d --name songwriter --network=host -p 8000:8000 -p 8265:8265 --shm-size=8g --env RAY_ACCEL_ENV_VAR_OVERRIDE_ON_ZERO=0 --env-file .env ai-songwriter

  http://localhost:8265 --- Ray Dashboard


docker run -d --name ray-head --network=host -p 8266:8265 --shm-size=8g rayproject/ray:2.10.0 ray start --head --dashboard-host=0.0.0.0 --port=10001 --object-manager-port=25343 --dashboard-port=8265

docker stop ray-head && docker rm ray-head


docker run -d --name songwriter --network=host -p 8000:8000 -p 8265:8265 --shm-size=8g --env RAY_ACCEL_ENV_VAR_OVERRIDE_ON_ZERO=0 --env-file .env songwriter

docker run -d --name ray_head -p 6379:6379 -p 8265:8265 --shm-size=8g rayproject/ray:latest-py312 ray start --head --port 6379 --dashboard-port 8265 --object-manager-port 8076 --node-manager-port 8077


docker run -d --name songwriter --network=host -p 8008:8000 -p 8265:8265 --shm-size=8g --env RAY_ACCEL_ENV_VAR_OVERRIDE_ON_ZERO=0 --env-file .env songwriter



docker run -d --name songwriter_test \
  -p 8008:8000 -p 8265:8265 \
  --shm-size=8g \
  --env RAY_ACCEL_ENV_VAR_OVERRIDE_ON_ZERO=0 \
  --env RAY_OVERRIDE_NODE_IP=0.0.0.0 \
  --env-file .env \
  songwriter


  Provide templated human content same structure as Suno
  Or provide Suno

Filled in like a madlib

With x number of lines for each section

  Both marked machine / human accordingly

Provide a real quick A-B for the user

Include the model author for each lines

